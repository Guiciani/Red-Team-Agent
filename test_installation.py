#!/usr/bin/env python3
"""
Script de teste para validar a instala√ß√£o e funcionamento do Red Team Agent
Executa testes b√°sicos sem necessidade de credenciais Azure
"""

import sys
import asyncio
import tempfile
import json
from pathlib import Path

def test_imports():
    """Testa se todas as importa√ß√µes necess√°rias est√£o funcionando"""
    print("üß™ Testando importa√ß√µes...")
    
    try:
        import requests
        import aiohttp
        import structlog
        from tabulate import tabulate
        from pydantic import BaseModel
        from dotenv import load_dotenv
        print("‚úÖ Depend√™ncias b√°sicas OK")
    except ImportError as e:
        print(f"‚ùå Erro nas depend√™ncias b√°sicas: {e}")
        return False
    
    try:
        from config import config, validate_config
        from utils import ReportAnalyzer, SecurityMetrics
        print("‚úÖ M√≥dulos locais OK")
    except ImportError as e:
        print(f"‚ùå Erro nos m√≥dulos locais: {e}")
        return False
    
    # Azure SDK √© opcional para testes
    try:
        from azure.ai.evaluation import RedTeam
        print("‚úÖ Azure AI Evaluation SDK OK")
    except ImportError:
        print("‚ö†Ô∏è Azure AI Evaluation SDK n√£o encontrado (normal em desenvolvimento)")
    
    return True

def test_configuration():
    """Testa se a configura√ß√£o est√° sendo carregada corretamente"""
    print("\\nüß™ Testando configura√ß√£o...")
    
    try:
        from config import config
        
        # Verifica estrutura da configura√ß√£o
        required_sections = ['azure', 'chatbot', 'redteam', 'logging', 'report']
        for section in required_sections:
            if section not in config:
                print(f"‚ùå Se√ß√£o '{section}' ausente na configura√ß√£o")
                return False
        
        print("‚úÖ Estrutura de configura√ß√£o OK")
        
        # Verifica categorias de risco
        if len(config['redteam'].risk_categories) >= 8:
            print("‚úÖ Categorias de risco configuradas")
        else:
            print("‚ö†Ô∏è Poucas categorias de risco configuradas")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro na configura√ß√£o: {e}")
        return False

async def test_demo_chatbot():
    """Testa se o chatbot demo responde corretamente"""
    print("\\nüß™ Testando chatbot demo...")
    
    try:
        import aiohttp
        
        # Tenta conectar com o chatbot demo (se estiver rodando)
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get('http://localhost:8000/health', timeout=aiohttp.ClientTimeout(total=2)) as response:
                    if response.status == 200:
                        print("‚úÖ Chatbot demo est√° rodando e respondendo")
                        
                        # Teste de prompt simples
                        async with session.post(
                            'http://localhost:8000/chat',
                            json={'prompt': 'Hello, this is a test'},
                            timeout=aiohttp.ClientTimeout(total=5)
                        ) as chat_response:
                            if chat_response.status == 200:
                                data = await chat_response.json()
                                print("‚úÖ Chatbot demo responde a prompts")
                                return True
                    
            except asyncio.TimeoutError:
                print("‚ö†Ô∏è Chatbot demo n√£o est√° rodando (execute: python demo_chatbot.py)")
                return True  # N√£o √© erro cr√≠tico
            except aiohttp.ClientConnectorError:
                print("‚ö†Ô∏è Chatbot demo n√£o est√° rodando")
                return True  # N√£o √© erro cr√≠tico
                
    except Exception as e:
        print(f"‚ùå Erro no teste do chatbot: {e}")
        return False

def test_report_generation():
    """Testa se a gera√ß√£o de relat√≥rios est√° funcionando"""
    print("\\nüß™ Testando gera√ß√£o de relat√≥rios...")
    
    try:
        from redteam_scan import AttackResult, ScanReport
        from utils import SecurityMetrics, create_mitigation_playbook
        from datetime import datetime
        
        # Cria dados de teste
        mock_results = [
            AttackResult(
                category="test_category",
                attack_prompt="Test prompt",
                target_response="Test response",
                is_blocked=False,
                is_successful=True,
                severity="medium",
                timestamp=datetime.now().isoformat(),
                execution_time_ms=100
            )
        ]
        
        mock_report = ScanReport(
            scan_id="test_scan_123",
            start_time=datetime.now().isoformat(),
            end_time=datetime.now().isoformat(),
            total_attacks=1,
            blocked_attacks=0,
            successful_attacks=1,
            failed_attacks=0,
            critical_vulnerabilities=[],
            results_by_category={"test_category": mock_results},
            recommendations=["Test recommendation"],
            scan_duration_seconds=10
        )
        
        # Testa m√©tricas de seguran√ßa
        scores = SecurityMetrics.calculate_security_score(mock_report.__dict__)
        risk_level = SecurityMetrics.assess_risk_level(scores)
        
        if scores and risk_level:
            print("‚úÖ C√°lculo de m√©tricas OK")
        
        # Testa playbook de mitiga√ß√£o
        playbook = create_mitigation_playbook(mock_results)
        if playbook and "immediate_actions" in playbook:
            print("‚úÖ Gera√ß√£o de playbook OK")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o de relat√≥rios: {e}")
        return False

def test_utils_functions():
    """Testa fun√ß√µes utilit√°rias"""
    print("\\nüß™ Testando utilit√°rios...")
    
    try:
        from utils import ReportAnalyzer, SecurityMetrics, export_to_csv
        
        # Verifica se as classes est√£o carregando
        analyzer = ReportAnalyzer()
        metrics = SecurityMetrics()
        
        print("‚úÖ Classes utilit√°rias OK")
        
        # Testa com dados mock
        mock_scores = {"overall": 75.0, "prompt_injection": 80.0}
        risk = SecurityMetrics.assess_risk_level(mock_scores)
        
        if risk in ["LOW", "MEDIUM", "HIGH", "CRITICAL"]:
            print("‚úÖ Avalia√ß√£o de risco OK")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro nos utilit√°rios: {e}")
        return False

async def run_basic_redteam_test():
    """Executa um teste b√°sico do Red Team Agent (sem Azure)"""
    print("\\nüß™ Testando Red Team Agent (modo offline)...")
    
    try:
        # Simula um teste b√°sico sem depend√™ncia do Azure
        from redteam_scan import RedTeamAgent
        
        # Mock das configura√ß√µes para teste
        import os
        os.environ['AZURE_CLIENT_ID'] = 'test'
        os.environ['AZURE_CLIENT_SECRET'] = 'test'
        os.environ['AZURE_TENANT_ID'] = 'test'
        os.environ['AZURE_OPENAI_ENDPOINT'] = 'test'
        os.environ['AZURE_OPENAI_API_KEY'] = 'test'
        
        # Cria agente (mas n√£o executa scan real)
        try:
            agent = RedTeamAgent()
            print("‚úÖ Red Team Agent inicializado")
            
            # Testa gera√ß√£o de prompts
            prompts = agent._generate_attack_prompts("prompt_injection")
            if len(prompts) > 0:
                print("‚úÖ Gera√ß√£o de prompts adversariais OK")
            
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è Red Team Agent requer configura√ß√£o Azure: {e}")
            return True  # N√£o √© erro cr√≠tico para teste
            
    except Exception as e:
        print(f"‚ùå Erro no teste do Red Team Agent: {e}")
        return False

def generate_test_report():
    """Gera um relat√≥rio de teste dos resultados"""
    print("\\nüìã RELAT√ìRIO DE TESTE")
    print("=" * 50)
    
    # Lista arquivos criados
    files_created = []
    for file_path in Path('.').glob('*.py'):
        if file_path.name in ['redteam_scan.py', 'config.py', 'utils.py', 'demo_chatbot.py', 'setup.py']:
            files_created.append(file_path.name)
    
    print(f"üìÅ Arquivos principais: {len(files_created)}")
    for file in files_created:
        print(f"   ‚úÖ {file}")
    
    # Verifica diret√≥rios
    if Path('reports').exists():
        print("üìÅ Diret√≥rio de relat√≥rios: ‚úÖ")
    else:
        print("üìÅ Diret√≥rio de relat√≥rios: ‚ö†Ô∏è (ser√° criado automaticamente)")
    
    if Path('.env.example').exists():
        print("üìÅ Template de configura√ß√£o: ‚úÖ")
    
    if Path('requirements.txt').exists():
        print("üìÅ Arquivo de depend√™ncias: ‚úÖ")
    
    print("\\nüéØ PR√ìXIMOS PASSOS:")
    print("1. Configure suas credenciais Azure no arquivo .env")
    print("2. Execute: python setup.py (para instala√ß√£o autom√°tica)")
    print("3. Execute: python demo_chatbot.py (em um terminal)")
    print("4. Execute: python redteam_scan.py (em outro terminal)")

async def main():
    """Fun√ß√£o principal de teste"""
    print("üî¥ RED TEAM AGENT - TESTE DE VALIDA√á√ÉO")
    print("=" * 60)
    
    tests = [
        ("Importa√ß√µes", test_imports),
        ("Configura√ß√£o", test_configuration),
        ("Relat√≥rios", test_report_generation),
        ("Utilit√°rios", test_utils_functions)
    ]
    
    async_tests = [
        ("Chatbot Demo", test_demo_chatbot),
        ("Red Team Agent", run_basic_redteam_test)
    ]
    
    passed = 0
    total = len(tests) + len(async_tests)
    
    # Executa testes s√≠ncronos
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                print(f"‚ùå Teste '{test_name}' falhou")
        except Exception as e:
            print(f"‚ùå Erro no teste '{test_name}': {e}")
    
    # Executa testes ass√≠ncronos
    for test_name, test_func in async_tests:
        try:
            if await test_func():
                passed += 1
            else:
                print(f"‚ùå Teste '{test_name}' falhou")
        except Exception as e:
            print(f"‚ùå Erro no teste '{test_name}': {e}")
    
    # Relat√≥rio final
    print(f"\\nüìä RESULTADO FINAL: {passed}/{total} testes passaram")
    
    if passed == total:
        print("üéâ Todos os testes passaram! Sistema est√° pronto.")
        generate_test_report()
        return 0
    elif passed >= total * 0.8:
        print("‚úÖ A maioria dos testes passou. Sistema quase pronto.")
        generate_test_report()
        return 0
    else:
        print("‚ö†Ô∏è V√°rios testes falharam. Verifique a instala√ß√£o.")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())