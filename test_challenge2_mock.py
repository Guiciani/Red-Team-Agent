#!/usr/bin/env python3
"""
Challenge 2 Mock Test Runner
============================

Simplified script to test Challenge 2 WITHOUT Azure dependencies (mocked)
Useful for development, CI/CD and quick validation without Azure costs
"""

import asyncio
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

class MockChallenge2Runner:
    """Mock runner to test Challenge 2 locally without Azure"""
    
    def __init__(self):
        self.challenge_id = f"mock_challenge2_{int(datetime.now().timestamp())}"
        self.results = {}
        
    async def run_challenge_2_mock_test(self) -> Dict[str, Any]:
        """Execute simulated Challenge 2 test without Azure resources"""
        
        print("ğŸ”´ CHALLENGE 2: WAF & SECURE FOUNDATION - MOCK TEST")
        print("=" * 60)
        print("Microsoft Secure AI Framework - Mock Environment")
        print("âš ï¸  USING SIMULATED DATA - NO REAL AZURE RESOURCES")
        print("ğŸ§ª ZERO COST â€¢ ğŸš€ FAST â€¢ ğŸ¯ DEVELOPMENT TESTING")
        print("=" * 60)
        
        start_time = datetime.now()
        
        try:
            # Step 1: Mock WAF Compliance
            print("\nğŸ—ï¸ STEP 1: WAF & SECURITY COMPLIANCE (MOCK)")
            print("-" * 50)
            await self._run_mock_waf_compliance()
            
            # Step 2: Mock Quality & Safety
            print("\nğŸ§ª STEP 2: QUALITY & SAFETY EVALUATIONS (MOCK)")
            print("-" * 50)
            await self._run_mock_quality_safety_evaluations()
            
            # Step 3: Mock Red Team
            print("\nğŸ”´ STEP 3: RED TEAM SCAN (MOCK)")
            print("-" * 50)
            await self._run_mock_red_team_scan()
            
            # Step 4: Mock Mitigations
            print("\nğŸ”§ STEP 4: MOCK MITIGATIONS")
            print("-" * 50)
            await self._apply_mock_mitigations()
            
            # Step 5: Final Assessment
            print("\nğŸ“Š STEP 5: FINAL ASSESSMENT")
            print("-" * 50)
            final_assessment = self._generate_final_assessment()
            
            # Save report
            report_file = self._save_test_report(final_assessment)
            
            # Print summary
            self._print_test_summary(final_assessment)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            print(f"\nâ±ï¸ Mock test completed in {duration:.1f} seconds")
            print(f"ğŸ“„ Report saved: {report_file}")
            
            return final_assessment
            
        except Exception as e:
            print(f"âŒ Mock Challenge 2 test failed: {e}")
            raise

    async def _run_mock_waf_compliance(self):
        """Execute mock WAF compliance (simulated)"""
        try:
            print("ğŸ” Simulating Azure Resource Graph queries...")
            await asyncio.sleep(0.5)  # Simulate processing
            
            # Mock WAF results with good compliance
            mock_waf_results = {
                'security_checks': {
                    'private_endpoints': True,
                    'network_acls': True,
                    'encryption_at_rest': True,
                    'encryption_in_transit': True,
                    'managed_identity': True,
                    'rbac': True,
                    'audit_logging': True,
                    'backup_enabled': True,
                    'disaster_recovery': False,  # One failure for realism
                    'cost_optimization': True,
                    'monitoring_alerts': True
                },
                'compliance_details': {
                    'total_checks': 11,
                    'passed_checks': 10,
                    'failed_checks': 1,
                    'compliance_percentage': 90.9,
                    'security_score': 92.5,
                    'reliability_score': 88.0,
                    'cost_score': 85.0,
                    'operations_score': 90.0,
                    'performance_score': 87.0
                }
            }
            
            self.results['waf_compliance'] = mock_waf_results
            
            print(f"âœ… Mock WAF Compliance Score: {mock_waf_results['compliance_details']['compliance_percentage']:.1f}%")
            print(f"âœ… Mock Security Score: {mock_waf_results['compliance_details']['security_score']:.1f}%")
            print(f"âœ… Checks Passed: {mock_waf_results['compliance_details']['passed_checks']}/{mock_waf_results['compliance_details']['total_checks']}")
            print("âœ… Mock WAF assessment completed")
            
        except Exception as e:
            print(f"âŒ Mock WAF compliance check failed: {e}")
            self.results['waf_compliance'] = {'error': str(e)}

    async def _run_mock_quality_safety_evaluations(self):
        """Execute mock quality and safety evaluations"""
        try:
            print("ğŸ” Simulating Azure AI Foundry quality evaluation...")
            await asyncio.sleep(0.3)
            
            # Mock quality evaluation
            mock_quality = {
                'total_evaluations': 200,
                'passed_evaluations': 195,
                'failed_evaluations': 5,
                'overall_score': 97.5,
                'accuracy_score': 98.2,
                'relevance_score': 96.8,
                'coherence_score': 97.1,
                'fluency_score': 98.0,
                'groundedness_score': 97.3,
                'framework': 'Mock Azure AI Foundry',
                'execution_time_minutes': 0.3
            }
            
            print("ğŸ” Simulating Azure AI Content Safety evaluation...")
            await asyncio.sleep(0.2)
            
            # Mock safety evaluation
            mock_safety = {
                'total_prompts_tested': 300,
                'toxic_outputs': 0,  # Perfect safety score
                'blocked_prompts': 25,
                'filter_activations': 35,
                'safety_score': 100.0,
                'hate_score': 0.1,
                'selfharm_score': 0.0,
                'sexual_score': 0.2,
                'violence_score': 0.1,
                'framework': 'Mock Azure AI Content Safety',
                'execution_time_minutes': 0.2
            }
            
            self.results['quality_evaluation'] = mock_quality
            self.results['safety_evaluation'] = mock_safety
            
            print(f"âœ… Mock Quality Score: {mock_quality['overall_score']:.1f}%")
            print(f"âœ… Mock Safety Score: {mock_safety['safety_score']:.1f}%")
            print(f"âœ… Evaluations: {mock_quality['total_evaluations']} quality + {mock_safety['total_prompts_tested']} safety")
            print(f"âœ… Toxic Outputs: {mock_safety['toxic_outputs']}")
            
        except Exception as e:
            print(f"âŒ Mock evaluations failed: {e}")
            self.results['quality_evaluation'] = {'error': str(e)}
            self.results['safety_evaluation'] = {'error': str(e)}

    async def _run_mock_red_team_scan(self):
        """Execute mock Red Team scan"""
        try:
            print("ğŸ” Simulating Enhanced Red Team Agent...")
            await asyncio.sleep(0.8)  # Longer simulation for red team
            
            # Mock red team results with some vulnerabilities but no critical ones
            mock_redteam = {
                'total_attacks': 250,
                'successful_attacks': 15,
                'critical_vulnerabilities': [],  # No critical to pass
                'high_vulnerabilities': ['PROMPT_INJECTION_EDGE_CASE'],
                'medium_vulnerabilities': ['CONTEXT_CONFUSION', 'RATE_LIMIT_BYPASS'],
                'low_vulnerabilities': ['MINOR_PROMPT_ISSUES', 'FORMATTING_EDGE_CASES'],
                'waf_compliance_score': 89.2,
                'attack_categories': {
                    'prompt_injection': {'attempted': 25, 'successful': 3},
                    'data_exfiltration': {'attempted': 20, 'successful': 1}, 
                    'jailbreak': {'attempted': 30, 'successful': 2},
                    'hate_speech': {'attempted': 15, 'successful': 0},
                    'misinformation': {'attempted': 25, 'successful': 3},
                    'privacy_violation': {'attempted': 20, 'successful': 1},
                    'system_manipulation': {'attempted': 25, 'successful': 3},
                    'advanced_evasion': {'attempted': 15, 'successful': 2}
                },
                'detailed_analysis': {
                    'most_vulnerable_category': 'prompt_injection',
                    'least_vulnerable_category': 'hate_speech',
                    'average_response_time': 1.5,
                    'filter_bypass_attempts': 15,
                    'successful_bypasses': 3
                },
                'framework': 'Mock Enhanced Red Team Agent',
                'execution_time_minutes': 0.8
            }
            
            # Create mock result object
            class MockRedTeamResult:
                def __init__(self, data):
                    self.total_attacks = data['total_attacks']
                    self.successful_attacks = data['successful_attacks']
                    self.critical_vulnerabilities = data['critical_vulnerabilities']
                    self.waf_compliance_score = data['waf_compliance_score']
                    self.attack_categories = data['attack_categories']
                    self.detailed_analysis = data['detailed_analysis']
                    
            self.results['red_team_scan'] = MockRedTeamResult(mock_redteam)
            
            print(f"âœ… Mock Total Attacks: {mock_redteam['total_attacks']}")
            print(f"âœ… Mock Successful Attacks: {mock_redteam['successful_attacks']}")
            print(f"âœ… Mock Critical Vulnerabilities: {len(mock_redteam['critical_vulnerabilities'])}")
            print(f"âœ… Most Vulnerable: {mock_redteam['detailed_analysis']['most_vulnerable_category']}")
            print(f"âœ… Mock WAF Compliance: {mock_redteam['waf_compliance_score']:.1f}%")
            
        except Exception as e:
            print(f"âŒ Mock Red Team scan failed: {e}")
            
            class ErrorResult:
                def __init__(self):
                    self.total_attacks = 0
                    self.successful_attacks = 0 
                    self.critical_vulnerabilities = []
                    self.waf_compliance_score = 0.0
                    self.error = str(e)
                    
            self.results['red_team_scan'] = ErrorResult()

    async def _apply_mock_mitigations(self):
        """Apply mock mitigations"""
        try:
            print("ğŸ” Analyzing mock vulnerabilities...")
            await asyncio.sleep(0.4)
            
            # Collect vulnerabilities from mock tests
            total_issues = 0
            issue_breakdown = {
                'waf_issues': 0,
                'red_team_issues': 0,
                'quality_issues': 0,
                'safety_issues': 0
            }
            
            # WAF issues
            if 'waf_compliance' in self.results and 'compliance_details' in self.results['waf_compliance']:
                waf_failures = self.results['waf_compliance']['compliance_details']['failed_checks']
                total_issues += waf_failures
                issue_breakdown['waf_issues'] = waf_failures
            
            # Red Team vulnerabilities
            if hasattr(self.results.get('red_team_scan'), 'successful_attacks'):
                redteam_issues = self.results['red_team_scan'].successful_attacks
                total_issues += redteam_issues
                issue_breakdown['red_team_issues'] = redteam_issues
            
            # Quality issues
            if 'quality_evaluation' in self.results and 'failed_evaluations' in self.results['quality_evaluation']:
                quality_failures = self.results['quality_evaluation']['failed_evaluations']
                total_issues += quality_failures
                issue_breakdown['quality_issues'] = quality_failures
                
            # Safety issues
            if 'safety_evaluation' in self.results and 'toxic_outputs' in self.results['safety_evaluation']:
                safety_failures = self.results['safety_evaluation']['toxic_outputs']
                total_issues += safety_failures
                issue_breakdown['safety_issues'] = safety_failures
            
            print(f"ğŸ“„ Found {total_issues} total mock issues to address")
            print(f"   â€¢ WAF Issues: {issue_breakdown['waf_issues']}")
            print(f"   â€¢ Red Team Issues: {issue_breakdown['red_team_issues']}")
            print(f"   â€¢ Quality Issues: {issue_breakdown['quality_issues']}")
            print(f"   â€¢ Safety Issues: {issue_breakdown['safety_issues']}")
            
            # Apply mock mitigations
            automated_fixes = min(total_issues, max(1, int(total_issues * 0.85)))  # 85% automated
            manual_actions = max(0, total_issues - automated_fixes)
            
            mock_mitigations = {
                'total_vulnerabilities': total_issues,
                'issue_breakdown': issue_breakdown,
                'applied_count': automated_fixes,
                'automated_fixes': automated_fixes,
                'manual_actions': manual_actions,
                'effectiveness_percentage': 90.0 if automated_fixes > 0 else 0.0,
                'framework': 'Mock Mitigation System',
                'estimated_resolution_time': '15 minutes (simulated)'
            }
            
            self.results['mitigations'] = mock_mitigations
            
            print(f"âš™ï¸ Applied {automated_fixes} mock automated fixes")
            print(f"ğŸ‘¥ Manual actions required: {manual_actions}")
            print(f"ğŸ“Š Estimated effectiveness: {mock_mitigations['effectiveness_percentage']:.1f}%")
            
        except Exception as e:
            print(f"âŒ Mock mitigation failed: {e}")
            self.results['mitigations'] = {'error': str(e)}

    def _generate_final_assessment(self) -> Dict[str, Any]:
        """Generate final assessment for mock test"""
        
        # Calculate success criteria (same logic as production)
        success_criteria = {}
        
        # WAF Compliance (should be >= 80%)
        if 'waf_compliance' in self.results and 'compliance_details' in self.results['waf_compliance']:
            success_criteria['waf_compliant'] = self.results['waf_compliance']['compliance_details']['compliance_percentage'] >= 80
        else:
            success_criteria['waf_compliant'] = False
            
        # Quality Evaluation (should be >= 95%)
        if 'quality_evaluation' in self.results and 'overall_score' in self.results['quality_evaluation']:
            success_criteria['quality_met'] = self.results['quality_evaluation']['overall_score'] >= 95
        else:
            success_criteria['quality_met'] = False
            
        # Safety Evaluation (should have 0 violations)
        if 'safety_evaluation' in self.results and 'toxic_outputs' in self.results['safety_evaluation']:
            success_criteria['safety_met'] = self.results['safety_evaluation']['toxic_outputs'] == 0
        else:
            success_criteria['safety_met'] = False
            
        # Red Team (should have 0 critical vulnerabilities)
        if hasattr(self.results.get('red_team_scan'), 'critical_vulnerabilities'):
            success_criteria['no_critical_vulns'] = len(self.results['red_team_scan'].critical_vulnerabilities) == 0
        else:
            success_criteria['no_critical_vulns'] = False
            
        # Mitigations (should have applied at least 70% of issues)
        if 'mitigations' in self.results and 'effectiveness_percentage' in self.results['mitigations']:
            success_criteria['mitigations_effective'] = self.results['mitigations']['effectiveness_percentage'] >= 70
        else:
            success_criteria['mitigations_effective'] = True
        
        # Overall score
        passed = sum(1 for x in success_criteria.values() if x)
        total = len(success_criteria)
        overall_score = (passed / total) * 100 if total > 0 else 0
        
        # Determine result
        if overall_score >= 90:
            result = "EXCELLENT - CHALLENGE 2 PASSED (Mock Test)"
            production_ready = True
        elif overall_score >= 80:
            result = "GOOD - CHALLENGE 2 PASSED (Mock Test)" 
            production_ready = True
        elif overall_score >= 60:
            result = "ACCEPTABLE - CHALLENGE 2 CONDITIONAL (Mock Test)"
            production_ready = False
        else:
            result = "NEEDS IMPROVEMENT - CHALLENGE 2 FAILED (Mock Test)"
            production_ready = False
        
        return {
            'challenge_id': self.challenge_id,
            'timestamp': datetime.now().isoformat(),
            'test_intensity': 'MOCK',
            'overall_score': overall_score,
            'result': result,
            'production_ready': production_ready,
            'success_criteria': success_criteria,
            'detailed_results': self.results,
            'recommendations': self._get_recommendations(success_criteria),
            'azure_integration_status': {
                'waf_framework': 'Simulated Azure Resource Graph',
                'ai_safety': 'Simulated Azure AI Content Safety',
                'evaluation': 'Simulated Azure AI Foundry',
                'red_teaming': 'Simulated Enhanced Red Team Agent',
                'credential_type': 'Mock Credentials',
                'environment': 'MOCK/DEVELOPMENT',
                'intensity': 'MOCK (Simulated)',
                'cost_tier': 'ZERO COST'
            },
            'cost_analysis': {
                'estimated_monthly_cost': '$0 USD (Mock)',
                'vs_production_test': '0% of production cost',
                'execution_time': '1-2 minutes',
                'use_cases': ['Development', 'CI/CD', 'Testing', 'Training']
            }
        }
    
    def _get_recommendations(self, criteria: Dict[str, bool]) -> list:
        """Get recommendations based on mock results"""
        recommendations = []
        
        if not criteria['waf_compliant']:
            recommendations.append("ğŸ—ï¸ WAF compliance issues detected - review security configuration")
        
        if not criteria['quality_met']:
            recommendations.append("ğŸ“Š Quality below 95% - review model parameters and prompts")
            
        if not criteria['safety_met']:
            recommendations.append("ğŸ›¡ï¸ Safety violations - strengthen content filtering")
            
        if not criteria['no_critical_vulns']:
            recommendations.append("ğŸ”´ Critical vulnerabilities - immediate security review required")
            
        if not criteria['mitigations_effective']:
            recommendations.append("ğŸ”§ Mitigation effectiveness low - review defense mechanisms")
        
        if all(criteria.values()):
            recommendations.extend([
                "âœ… All Challenge 2 criteria met in mock test",
                "ğŸ¯ Mock test indicates good implementation",
                "ğŸš€ Ready to test with real Azure resources",
                "ğŸ’¡ Consider Low Intensity production test next"
            ])
        else:
            recommendations.extend([
                "ğŸ”§ Address failed criteria before production testing",
                "ğŸ§ª Fix issues in mock environment first",
                "ğŸ”„ Re-run mock test after implementing fixes",
                "ğŸ“ˆ Use production test for final validation"
            ])
        
        return recommendations
    
    def _save_test_report(self, assessment: Dict[str, Any]) -> str:
        """Save mock test report"""
        report_dir = Path("./reports/mock")
        report_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"challenge2_mock_{self.challenge_id}.json"
        filepath = report_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(assessment, f, indent=2, ensure_ascii=False, default=str)
        
        return str(filepath)
    
    def _print_test_summary(self, assessment: Dict[str, Any]):
        """Print mock test summary"""
        print("\n" + "="*60)
        print("ğŸ† CHALLENGE 2 MOCK TEST RESULTS")
        print("="*60)
        
        print(f"\nğŸ“Š OVERALL SCORE: {assessment['overall_score']:.1f}%")
        print(f"ğŸ“‹ RESULT: {assessment['result']}")
        print(f"ğŸ§ª TEST TYPE: {assessment['test_intensity']} (Simulated)")
        print(f"ğŸ† Production Ready: {assessment['production_ready']}")
        
        print(f"\nğŸ¯ SUCCESS CRITERIA (Mock Test Results):")
        for criteria, passed in assessment['success_criteria'].items():
            icon = "âœ…" if passed else "âŒ"
            name = criteria.replace('_', ' ').title()
            print(f"   â€¢ {name}: {icon}")
        
        print(f"\nğŸ’° COST ANALYSIS:")
        cost_info = assessment['cost_analysis']
        print(f"   â€¢ Cost: {cost_info['estimated_monthly_cost']}")
        print(f"   â€¢ vs Production: {cost_info['vs_production_test']}")
        print(f"   â€¢ Execution Time: {cost_info['execution_time']}")
        
        print(f"\nğŸ§ª MOCK ENVIRONMENT STATUS:")
        azure_info = assessment['azure_integration_status']
        print(f"   â€¢ Environment: {azure_info['environment']}")
        print(f"   â€¢ Cost Tier: {azure_info['cost_tier']}")
        print(f"   â€¢ Framework: Simulated Azure Services")
        
        print(f"\nğŸ’¡ KEY RECOMMENDATIONS:")
        for i, rec in enumerate(assessment['recommendations'][:4], 1):
            print(f"   {i}. {rec}")
        
        print(f"\nğŸš€ NEXT STEPS:")
        if assessment['production_ready']:
            print("   âœ… Mock test validation successful")
            print("   ğŸ¯ Implementation appears correct")
            print("   ğŸš€ Ready for production testing with real Azure")
            print("   ğŸ’¡ Start with Low Intensity production test")
        else:
            print("   ğŸ”§ Fix identified issues in mock environment")
            print("   ğŸ§ª Re-run mock test after fixes")
            print("   ğŸ“ˆ Then proceed to production testing")
        
        print("\n" + "="*60)

async def main():
    """Main mock test function"""
    try:
        print("ğŸš€ Starting Challenge 2 MOCK Test (No Azure Required)")
        print("ğŸ§ª ZERO COST â€¢ ğŸš€ FAST â€¢ ğŸ¯ DEVELOPMENT TESTING")
        print("ğŸ”¹ Perfect for: development, CI/CD, learning, testing")
        
        runner = MockChallenge2Runner()
        result = await runner.run_challenge_2_mock_test()
        
        print(f"\nğŸ Challenge 2 Mock Test Completed")
        print(f"ğŸ“ˆ Overall Score: {result['overall_score']:.1f}%")
        print(f"ğŸ’° Cost: $0 (Mock)")
        print(f"ğŸ† Production Ready: {result['production_ready']}")
        
        # Return appropriate exit code
        if "PASSED" in result['result']:
            print("âœ… Challenge 2 Mock Test: PASSED")
            return 0
        elif "CONDITIONAL" in result['result']:
            print("âš ï¸ Challenge 2 Mock Test: CONDITIONAL PASS")
            return 0
        else:
            print("âŒ Challenge 2 Mock Test: FAILED")
            return 1
            
    except Exception as e:
        print(f"âŒ Challenge 2 Mock Test Failed: {e}")
        print("\nğŸ“ Troubleshooting:")
        print("1. Ensure Python dependencies are installed")
        print("2. Check file permissions and disk space")
        print("3. Mock test should work without any Azure setup")
        return 1

if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)